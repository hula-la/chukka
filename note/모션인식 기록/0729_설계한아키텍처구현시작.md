## 1. HTTP í†µì‹  - ê°•ì‚¬ ì˜ìƒ

https://stribny.name/blog/fastapi-video/

##### FrontEnd

```html
<!DOCTYPE html>
<html>
    <head>
        <title>FastAPI video streaming</title>
    </head>
    <body>
        <video width="1200" controls muted="muted">
            <source src="http://localhost:8000/video" type="video/mp4" />
        </video>
    </body>
</html>
```



---

##### 	websocketì´ ì•„ë‹Œ ì‹¤ì‹œê°„ ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë°

â€‹	https://access-violation.tistory.com/17

---

##### - ê³µì‹ë¬¸ì„œ ì°¸ê³ í•´ì„œ ì˜ìƒ ë³´ë‚´ê¸° ì„±ê³µ

- **html**: `index_2.html`
- **fastAPI**: `fastapi_prac.py`

https://fastapi.tiangolo.com/ko/advanced/custom-response/?h=video#using-streamingresponse-with-file-like-objects

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

some_file_path = "large-video-file.mp4"
app = FastAPI()


@app.get("/")
def main():
    def iterfile():  # 
        with open(some_file_path, mode="rb") as file_like:  # 
            yield from file_like  # 

    return StreamingResponse(iterfile(), media_type="video/mp4")
```

- ê³µì‹ë¬¸ì„œì—ì„œ ì´ ì™¸ì˜ ì½”ë“œë“¤ ì¤‘ì—ì„œë„ ì°¸ê³ í•  ì½”ë“œ ìˆëŠ”ì§€ ë³´ê¸°
- ê¸°ì¡´ì˜ ì›¹ì†Œì¼“í†µì‹ ë„ HTTPë¡œ ê°€ëŠ¥í•œì§€ ë³´ê¸°

---

## 2. ì‹±í¬ ë§ì¶”ê¸°

#### ê¸°ì¡´ì˜ ê°•ì‚¬ ìì„¸ ë°ì´í„° ì¶”ì¶œ ì½”ë“œ ê°œì„ 

##### a. ê¹ƒí´ë”ì— ê°€ìƒí™˜ê²½ì´ë‘ ì „ì²´ ì˜®ê¹€

- `No module named '_pafprocess'
  you need to build c++ library for pafprocess. See : https://github.com/ildoonet/tf-pose-estimation/tree/master/tf_pose/pafprocess`

  ì—ëŸ¬ê°€ ë– ì„œ ì•„ë˜ ëª…ë ¹ìœ¼ë¡œ í™˜ê²½ì„¤ì •

  ```bash
  cd tf_pose/pafprocess
  swig -python -c++ pafprocess.i && python setup.py build_ext --inplace
  ```

  

##### b. OpenCV API ì„œì¹­ (https://deepflowest.tistory.com/107)

- ##### ë™ì˜ìƒ ë° ì¹´ë©”ë¼ í”„ë ˆì„ ì½ê¸°

  - `cap = cv2.VideoCaputure(file_path ë˜ëŠ” index)` : ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ìƒì„±

    - file_path : ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ
    - index : ì¹´ë©”ë¼ ì¥ì¹˜ ë²ˆí˜¸ (0 ë¶€í„° ì°¨ë¡€ë¡œ ì¦ê°€)
    - cap : VideoCapture ê°ì²´

    - `ret = cap.isOpened()` : ê°ì²´ ì´ˆê¸°í™” í™•ì¸
      - ret : ì´ˆê¸°í™” ì—¬ë¶€, True/False

    - `ret, img = cap.read() : ì˜ìƒ í”„ë ˆì„ ì½ê¸°`
      - ret : í”„ë ˆì„ ì½ê¸° ì„±ì†¡ ë˜ëŠ” ì‹¤íŒ¨ ì—¬ë¶€, True / False
      - img : í”„ë ˆì„ ì´ë¯¸ì§€, Numpy ë°°ì—´ ë˜ëŠ” None

  - `cap.set(id, value)` : í”„ë¡œí¼í‹° ë³€ê²½

  - `cap.get(id)` : í”„ë¡œí¼í‹° í™•ì¸

  - `cap.release()` : ê°ì²´ ìì› ë°˜ë‚©

- ##### ì¹´ë©”ë¼ ë¹„ë””ì˜¤ ì†ì„± ì œì–´

  - cv2.CAP_PROP_FRAME_WIDTH : í”„ë ˆì„ í­
  - cv2.CAP_PROP_FRAME_HEIGHT : í”„ë ˆì„ ë†’ì´
  - cv2.CAP_PROP_FPS : í”„ë ˆì„ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜
  - cv2.CAP_PROP_POS_MSEC : ë™ì˜ìƒ íŒŒì¼ì˜ í”„ë ˆì„ ìœ„ì¹˜(MS)
  - cv2.CAP_PROP_POS_AVI_RATIO : ë™ì˜ìƒ íŒŒì¼ì˜ ìƒëŒ€ ìœ„ì¹˜ (0:ì‹œì‘ , 1:ë)
  - cv2.CAP_PROP_FOURCC : ë™ì˜ìƒ íŒŒì¼ ì½”ë± ë¬¸ì
  - cv2.CAP_PROP_AUTOFOCUS : ì¹´ë©”ë¼ ìë™ ì´ˆì  ì¡°ì ˆ
  - cv2.CAP_PROP_ZOOM : ì¹´ë©”ë¼ ì¤Œ

- ##### FPSë¥¼ ì§€ì •í•´ì„œ ë™ì˜ìƒ ì¬ìƒ

  - ë™ì˜ìƒì˜ FPSë¥¼ êµ¬í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ ì ì ˆí•œ ì§€ì—° ì‹œê°„ì„ ê³„ì‚°í•´ì„œ ì§€ì •í•  ìˆ˜ ìˆë‹¤.

    ```python
    fps = cap.get(cv2.CP_PROP_FPS)
    delay = int(1000/fps)
    ```

    ```python
    import cv2
    
    video_file = "img/a.mp4"
    
    cap = cv2.VideoCapture(video_file)
    if cap.isOpened():
    	fps = cap.get(cv2.CAP_PROP_FPS)
        delay = int(1000/fps)
        print("FPS: %f, Delay: %dms" %(fps, delay))
        
        while True:
            ret, img = cap.read()
            if ret:
                cv2.imshow(video_file, img)
                cv2.waitKey(delay)
            else:
                break
    else:
    	print("can't open video")
    cap.release()
    cv2.destroyAllWindows()
    ```

##### c. ì½”ë“œ ìˆ˜ì •

- ê¸°ì¡´ì—” ê°•ì‚¬ ìì„¸ ì¢Œí‘œ ê°¯ìˆ˜ê°€ ì‹¤ì œ ì¶”ì¶œë˜ì–´ì•¼í•  í”„ë ˆì„ ìˆ˜ì™€ ë‹¬ëìŒ. 3400ì •ë„
  - ì½”ë“œ ë¶„ì„ í›„ ìˆ˜ì • ì™„ë£Œ 
    - ì˜ìƒê¸¸ì´ 21ì´ˆ
    - FPS 10 ì„¤ì •
    - **ì¶”ì¶œëœ í”„ë ˆì„ ê°¯ìˆ˜ 214** ğŸ‘

- `dance_video_processing`

  ```python
  def dance_video_processing(video_path= r'dance_video/correct30.mp4',showBG = True):
  
      cap = cv2.VideoCapture(video_path)
      video_fps = cap.get(cv2.CAP_PROP_FPS)
      # delay ì¶”ê°€, ì‹¤ì œ ë¹„ë””ì˜¤ fpsë¡œ ì¡°ì ˆí•¨
      delay = int(1000/video_fps)
  
      if cap.isOpened() is False:
          print("Error opening video stream or file")
  
      # prev_time = 0 -> ë§¨ì²˜ìŒ ì‹œê°„ ì´ˆê¸°í™” ìˆ˜ì •
      prev_time = time.time()
      FPS = 10
      keypoints_list=[]
      
      while True:
          ret_val, image = cap.read()
          current_time = time.time() - prev_time
          dim = (368, 428)
          if (ret_val is True) and (current_time > 1./FPS) :
              image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)
              humans = e.inference(image,
                                   resize_to_default=(w > 0 and h > 0),
                                   upsample_size=4.0)
              if not showBG:
                  image = np.zeros(image.shape)
  
              image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)
              npimg = np.copy(image)
              image_h, image_w = npimg.shape[:2]
              centers = {}
              
              for human in humans:
                      for i in range(common.CocoPart.Background.value):
                              if i not in human.body_parts.keys():
                                      continue
                              body_part = human.body_parts[i]
                              x_axis=int(body_part.x * image_w + 0.5)
                              y_axis=int(body_part.y * image_h + 0.5) 
                              center=[x_axis,y_axis]
                              centers[i] = center
                      # ìˆ˜ì • : í•œ ë¬¶ìŒì´ append ë˜ë„ë¡ ìˆ˜ì •
                      keypoints_list.append(centers)
  
              cv2.putText(image, "FPS: %f" % (1.0 / (time.time() - prev_time)), (10, 10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
              
              cv2.imshow('Dancer', image) 
  
              prev_time = time.time() 
  
              if cv2.waitKey(1) & 0xFF == ord('q'):
                  break
            
          elif (ret_val is False) :
              break
          else:
              # cv2.waitKey(1) => ë°ì´í„° ë¶„ì„ ì•ˆí•  ë•ŒëŠ” delay ì´ˆ ë§Œí¼ ì§€ì—°ë˜ë„ë¡ ìˆ˜ì •
              image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)
              cv2.imshow('Dancer', image) 
              cv2.waitKey(delay)
              
      print(len(keypoints_list))
      cap.release()
      cv2.destroyAllWindows()
      return keypoints_list
  ```

  

##### d. ëŒ„ì„œ ìì„¸ ë°ì´í„° csv ì…ì¶œë ¥

- ì €ì¥

  ```python
  data.to_csv("dancer_keyp_list.csv", index=False, header=False)
  ```

- ì½ê¸°

  ```python
  keyp_list=np.genfromtxt("dancer_keyp_list.csv",delimiter=",")
  ```

  

##### e. FPS ìˆ˜ì •

- ì‹¤ì œ ì˜ˆìƒ í”„ë ˆì„ ìˆ˜ì™€ ì•½ê°„ ì°¨ì´ê°€ ìƒê¹€
  - ì´ì „ì—” ê´œì°®ì•˜ëŠ”ë°, ê°‘ìê¸° 210->190 ì •ë„ë¡œ ì¤„ì–´ë“¦
  - ë¶„ì„í•  ë•Œ ì‹¤ì œ FPSë³´ë‹¤ ëŠë ¤ì„œ ìƒê¸°ëŠ” ë”œë ˆì´ê°™ì•„ì„œ FPSë¥¼ 5ë¡œ ì¤„ì´ë‹ˆ 105ë¡œ ì˜ˆìƒ í”„ë ˆì„ ìˆ˜ì™€ ê°™ì•„ì§.



##### f. ì›¹ì†Œì¼“ ì¢…ë£Œ í›„ í´ë¼ì´ì–¸íŠ¸ì—ì„œ setInterval ì¢…ë£Œ

- ì„œë²„ì—ì„œ ëŒ„ì„œì˜ìƒì´ ëë‚˜ë©´ `close` ì—ëŸ¬ê°€ ê³„ì† ëœ¸ â†’ ì´ê±° ìˆ˜ì •

  ```html
  <!--videosender.html-->
  <!DOCTYPE html>
  <html>
  <head>
  	<title>Hello</title>
  </head>
  <body>
  	<video id="videoInput" style="display:none"></video>
    <img id="my_video" width="200" src="">
    <video id="dancer_video" width="200" controls muted="muted">
      <source src="http://localhost:8000/game/dancer" type="video/mp4"/>
  </video>
    <canvas id="videoOutput"></canvas>
    <button onclick=stream()>Send</button>
  </body>
  <script>
    var w = 320, h = 240;
      var url = "ws://localhost:8000/client"
      var ws = new WebSocket(url);
      var FPS=5;
      let interval;
  
    ws.binaryType = "arraybuffer";
  
    // websocket ì—°ê²°
  	ws.onopen = function(){
  		console.log("Websocket is connected.");
  	}
  
  
  
    
  	ws.onmessage = function(msg){
  		// console.log(msg.data);
      var arrayBufferView = new Uint8Array( msg.data);
      var blob = new Blob( [ arrayBufferView ], { type: "multipart/x-mixed-replace" } );
      var urlCreator = window.URL || window.webkitURL;
      var imageUrl = urlCreator.createObjectURL( blob );
      var img = document.querySelector( "#my_video" );
      img.src = imageUrl;
  	}
  
  
      ws.onclose = function(event) {
          if (event.wasClean) {
              clearInterval(interval);
              alert(`[close] ì»¤ë„¥ì…˜ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤(code=${event.code} reason=${event.reason})`);
          } else {
              // ì˜ˆì‹œ: í”„ë¡œì„¸ìŠ¤ê°€ ì£½ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ì— ì¥ì• ê°€ ìˆëŠ” ê²½ìš°
              // event.codeê°€ 1006ì´ ë©ë‹ˆë‹¤.
              alert('[close] ì»¤ë„¥ì…˜ì´ ì£½ì—ˆìŠµë‹ˆë‹¤.');
          }
      };
  
  
  	navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
    var constraints = {audio: false, video: true};
    var video = document.getElementById("videoInput");
    video.width = w;
    video.height = h;
    function successCallback(stream){
    	video.srcObject = stream;
    	video.play();
    }
    
    function errorCallback(error){
     	console.log(error);
    }
    navigator.getUserMedia(constraints, successCallback, errorCallback);
  	var canvas = document.getElementById("videoOutput");				
    canvas.width = w;
    canvas.height = h;
    var ctx = canvas.getContext("2d");
  
    function processImage(){
          ctx.drawImage(video, 0, 0, w, h);
          setTimeout(processImage, 1);
    }
  
    processImage();
  
    function stream(){
      document.getElementById("dancer_video").play();
  
      interval = setInterval(sendImage, 1000/FPS);
    }
  
    function sendImage(){
      var rawData = canvas.toDataURL("image/jpeg", 0.5);
      ws.send(rawData);
    }
  
  
   
  /* later */
  
  
  </script>
  </html>
  ```

  