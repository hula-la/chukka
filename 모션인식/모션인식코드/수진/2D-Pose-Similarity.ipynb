{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "\n",
    "As input to the system, take the live feed from the webcam and use pose estimation to map out a small dance tutorial.\n",
    "\n",
    "# Approach:\n",
    "- We will take a pretrained **openpose estimation model** to prdict the **18 keypoints** on a human body.\n",
    "- We take openpose model for tensorflow by Ildoo Kim\n",
    "  - GitHub Repo Link: https://github.com/ildoonet/tf-pose-estimation\n",
    "<br>**[!] Note**: Some how I found issues with this repo to work with tensorflow 2.0 and followed a modified repo of his by Gunjan Seth.<br>\n",
    "GitHub Repo Link: https://github.com/gsethi2409/tf-pose-estimation\n",
    "<br>Medium Blog by Gunjan Seth: https://medium.com/@gsethi2409/pose-estimation-with-tensorflow-2-0-a51162c095ba\n",
    "- The keypoints of the dancer are obtained and stored in a array list.\n",
    "- These keypoints are **normalized**.\n",
    "- The user feed is taken and the keypoints are detected.\n",
    "- The keypoints are normalized and the **cosine similarity** is found between the user keypoints and the array of dancer keypoints.\n",
    "- The minimum similarity score is **compared with the threshold** and then it displays is the user steps are correct or not for the given dancer moves.\n",
    "\n",
    "# Constraints To Look For:\n",
    "1. The model should be fast for prediction. Latency should be avoided.\n",
    "2. Predictions should be accurate and the steps should be close enough with  the dancer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T01:36:55.787005Z",
     "start_time": "2020-08-02T01:36:49.577066Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and TfPose Estimator\n",
    "We initialize the pretrained model with the required parameters as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T21:22:38.309068Z",
     "start_time": "2020-08-01T21:22:38.305690Z"
    }
   },
   "outputs": [],
   "source": [
    "camera = 0\n",
    "resize = '432x368'     # resize images before they are processed\n",
    "resize_out_ratio = 4.0 # resize heatmaps before they are post-processed\n",
    "model='mobilenet_v2_large'\n",
    "show_process = False\n",
    "tensorrt = False       # for tensorrt process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T21:22:41.609884Z",
     "start_time": "2020-08-01T21:22:39.578436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-07-27 11:42:03,713] [TfPoseEstimator] [INFO] loading graph from c:\\Users\\SSAFY\\Desktop\\모션인식\\models\\graph/mobilenet_v2_large/graph_opt.pb(default size=432x368)\n",
      "2022-07-27 11:42:03,713 INFO loading graph from c:\\Users\\SSAFY\\Desktop\\모션인식\\models\\graph/mobilenet_v2_large/graph_opt.pb(default size=432x368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfPoseEstimator/image\n",
      "TfPoseEstimator/MobilenetV2/Conv/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/Conv/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/Const_1\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/project/BatchNorm/Const\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/project/BatchNorm/Const_1\n",
      "TfPoseEstimator/strided_slice/stack\n",
      "TfPoseEstimator/strided_slice/stack_1\n",
      "TfPoseEstimator/strided_slice/stack_2\n",
      "TfPoseEstimator/feat_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/BatchNorm/Const\n",
      "TfPoseEstimator/Openpose/concat_stage7/axis\n",
      "TfPoseEstimator/MobilenetV2/Conv/BatchNorm/beta/read/_0__cf__0\n",
      "TfPoseEstimator/MobilenetV2/Conv/BatchNorm/gamma/read/_1__cf__1\n",
      "TfPoseEstimator/MobilenetV2/Conv/weights/read/_2__cf__2\n",
      "TfPoseEstimator/MobilenetV2/Conv/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/Conv/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/Conv/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/read/_3__cf__3\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/read/_4__cf__4\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/depthwise_weights/read/_5__cf__5\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/project/BatchNorm/beta/read/_6__cf__6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/project/BatchNorm/gamma/read/_7__cf__7\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/project/weights/read/_8__cf__8\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/read/_9__cf__9\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/read/_10__cf__10\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/read/_11__cf__11\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/read/_12__cf__12\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/read/_13__cf__13\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/weights/read/_14__cf__14\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/read/_15__cf__15\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/read/_16__cf__16\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/project/weights/read/_17__cf__17\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_1/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/read/_18__cf__18\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/read/_19__cf__19\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/read/_20__cf__20\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/read/_21__cf__21\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/read/_22__cf__22\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/weights/read/_23__cf__23\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/read/_24__cf__24\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/read/_25__cf__25\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/project/weights/read/_26__cf__26\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta/read/_27__cf__27\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma/read/_28__cf__28\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/read/_29__cf__29\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta/read/_30__cf__30\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma/read/_31__cf__31\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/weights/read/_32__cf__32\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/project/BatchNorm/beta/read/_33__cf__33\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma/read/_34__cf__34\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/project/weights/read/_35__cf__35\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta/read/_36__cf__36\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma/read/_37__cf__37\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/read/_38__cf__38\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta/read/_39__cf__39\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma/read/_40__cf__40\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/weights/read/_41__cf__41\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/project/BatchNorm/beta/read/_42__cf__42\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma/read/_43__cf__43\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/project/weights/read/_44__cf__44\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta/read/_45__cf__45\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma/read/_46__cf__46\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/read/_47__cf__47\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta/read/_48__cf__48\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma/read/_49__cf__49\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/weights/read/_50__cf__50\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/project/BatchNorm/beta/read/_51__cf__51\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma/read/_52__cf__52\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/project/weights/read/_53__cf__53\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_2/add\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta/read/_54__cf__54\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma/read/_55__cf__55\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/read/_56__cf__56\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta/read/_57__cf__57\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma/read/_58__cf__58\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/weights/read/_59__cf__59\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/project/BatchNorm/beta/read/_60__cf__60\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma/read/_61__cf__61\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/project/weights/read/_62__cf__62\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_3/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta/read/_63__cf__63\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma/read/_64__cf__64\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/read/_65__cf__65\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta/read/_66__cf__66\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma/read/_67__cf__67\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/weights/read/_68__cf__68\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/project/BatchNorm/beta/read/_69__cf__69\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma/read/_70__cf__70\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/project/weights/read/_71__cf__71\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_4/add\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta/read/_72__cf__72\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma/read/_73__cf__73\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/read/_74__cf__74\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta/read/_75__cf__75\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma/read/_76__cf__76\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/weights/read/_77__cf__77\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/project/BatchNorm/beta/read/_78__cf__78\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma/read/_79__cf__79\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/project/weights/read/_80__cf__80\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_5/add\n",
      "TfPoseEstimator/Shape\n",
      "TfPoseEstimator/strided_slice\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta/read/_81__cf__81\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma/read/_82__cf__82\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/read/_83__cf__83\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta/read/_84__cf__84\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma/read/_85__cf__85\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/weights/read/_86__cf__86\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/project/BatchNorm/beta/read/_87__cf__87\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma/read/_88__cf__88\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/project/weights/read/_89__cf__89\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_6/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta/read/_90__cf__90\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma/read/_91__cf__91\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/read/_92__cf__92\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta/read/_93__cf__93\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma/read/_94__cf__94\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/weights/read/_95__cf__95\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/project/BatchNorm/beta/read/_96__cf__96\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma/read/_97__cf__97\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/project/weights/read/_98__cf__98\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_7/add\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta/read/_99__cf__99\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma/read/_100__cf__100\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/read/_101__cf__101\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta/read/_102__cf__102\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma/read/_103__cf__103\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/weights/read/_104__cf__104\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/project/BatchNorm/beta/read/_105__cf__105\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma/read/_106__cf__106\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/project/weights/read/_107__cf__107\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_8/add\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta/read/_108__cf__108\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma/read/_109__cf__109\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/read/_110__cf__110\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta/read/_111__cf__111\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma/read/_112__cf__112\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/weights/read/_113__cf__113\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/project/BatchNorm/beta/read/_114__cf__114\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma/read/_115__cf__115\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/project/weights/read/_116__cf__116\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_9/add\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_10/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_11/add\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/expand/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/depthwise/Relu6\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/project/Conv2D\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/project/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV2/expanded_conv_12/add\n",
      "TfPoseEstimator/base/layer_14/output/upsample\n",
      "TfPoseEstimator/feat_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_depthwise/depthwise_weights/read/_117__cf__117\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/BatchNorm/beta/read/_118__cf__118\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/BatchNorm/moving_mean/read/_119__cf__119\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/BatchNorm/moving_variance/read/_120__cf__120\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/weights/read/_121__cf__121\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_depthwise/depthwise_weights/read/_122__cf__122\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/BatchNorm/beta/read/_123__cf__123\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/BatchNorm/moving_mean/read/_124__cf__124\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/BatchNorm/moving_variance/read/_125__cf__125\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/weights/read/_126__cf__126\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_depthwise/depthwise_weights/read/_127__cf__127\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/BatchNorm/beta/read/_128__cf__128\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/BatchNorm/moving_mean/read/_129__cf__129\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/BatchNorm/moving_variance/read/_130__cf__130\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/weights/read/_131__cf__131\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_depthwise/depthwise_weights/read/_132__cf__132\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/BatchNorm/beta/read/_133__cf__133\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/BatchNorm/moving_mean/read/_134__cf__134\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/BatchNorm/moving_variance/read/_135__cf__135\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/weights/read/_136__cf__136\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_depthwise/depthwise_weights/read/_137__cf__137\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/BatchNorm/beta/read/_138__cf__138\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/BatchNorm/moving_mean/read/_139__cf__139\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/BatchNorm/moving_variance/read/_140__cf__140\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/weights/read/_141__cf__141\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_depthwise/depthwise_weights/read/_142__cf__142\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/BatchNorm/beta/read/_143__cf__143\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/BatchNorm/moving_mean/read/_144__cf__144\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/BatchNorm/moving_variance/read/_145__cf__145\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/weights/read/_146__cf__146\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_depthwise/depthwise_weights/read/_147__cf__147\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/BatchNorm/beta/read/_148__cf__148\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/BatchNorm/moving_mean/read/_149__cf__149\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/BatchNorm/moving_variance/read/_150__cf__150\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/weights/read/_151__cf__151\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_depthwise/depthwise_weights/read/_152__cf__152\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/BatchNorm/beta/read/_153__cf__153\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/BatchNorm/moving_mean/read/_154__cf__154\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/BatchNorm/moving_variance/read/_155__cf__155\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/weights/read/_156__cf__156\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_depthwise/depthwise_weights/read/_157__cf__157\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/BatchNorm/beta/read/_158__cf__158\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/BatchNorm/moving_mean/read/_159__cf__159\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/BatchNorm/moving_variance/read/_160__cf__160\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/weights/read/_161__cf__161\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_depthwise/depthwise_weights/read/_162__cf__162\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/BatchNorm/beta/read/_163__cf__163\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/BatchNorm/moving_mean/read/_164__cf__164\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/BatchNorm/moving_variance/read/_165__cf__165\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/weights/read/_166__cf__166\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_depthwise/depthwise_weights/read/_167__cf__167\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/BatchNorm/beta/read/_168__cf__168\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/BatchNorm/moving_mean/read/_169__cf__169\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/BatchNorm/moving_variance/read/_170__cf__170\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/weights/read/_171__cf__171\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_depthwise/depthwise_weights/read/_172__cf__172\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/BatchNorm/beta/read/_173__cf__173\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/BatchNorm/moving_mean/read/_174__cf__174\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/BatchNorm/moving_variance/read/_175__cf__175\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/weights/read/_176__cf__176\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_depthwise/depthwise_weights/read/_177__cf__177\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/BatchNorm/beta/read/_178__cf__178\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/BatchNorm/moving_mean/read/_179__cf__179\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/BatchNorm/moving_variance/read/_180__cf__180\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/weights/read/_181__cf__181\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_depthwise/depthwise_weights/read/_182__cf__182\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/BatchNorm/beta/read/_183__cf__183\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/BatchNorm/moving_mean/read/_184__cf__184\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/BatchNorm/moving_variance/read/_185__cf__185\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/weights/read/_186__cf__186\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_depthwise/depthwise_weights/read/_187__cf__187\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/BatchNorm/beta/read/_188__cf__188\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/BatchNorm/moving_mean/read/_189__cf__189\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/BatchNorm/moving_variance/read/_190__cf__190\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/weights/read/_191__cf__191\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_depthwise/depthwise_weights/read/_192__cf__192\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/BatchNorm/beta/read/_193__cf__193\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/BatchNorm/moving_mean/read/_194__cf__194\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/BatchNorm/moving_variance/read/_195__cf__195\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/weights/read/_196__cf__196\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_depthwise/depthwise_weights/read/_197__cf__197\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/BatchNorm/beta/read/_198__cf__198\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/BatchNorm/moving_mean/read/_199__cf__199\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/BatchNorm/moving_variance/read/_200__cf__200\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/weights/read/_201__cf__201\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_depthwise/depthwise_weights/read/_202__cf__202\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/BatchNorm/beta/read/_203__cf__203\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/BatchNorm/moving_mean/read/_204__cf__204\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/BatchNorm/moving_variance/read/_205__cf__205\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/weights/read/_206__cf__206\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_depthwise/depthwise_weights/read/_207__cf__207\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/BatchNorm/beta/read/_208__cf__208\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/BatchNorm/moving_mean/read/_209__cf__209\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/BatchNorm/moving_variance/read/_210__cf__210\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/weights/read/_211__cf__211\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_depthwise/depthwise_weights/read/_212__cf__212\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/BatchNorm/beta/read/_213__cf__213\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/BatchNorm/moving_mean/read/_214__cf__214\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/BatchNorm/moving_variance/read/_215__cf__215\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/weights/read/_216__cf__216\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_depthwise/depthwise_weights/read/_217__cf__217\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/BatchNorm/beta/read/_218__cf__218\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/BatchNorm/moving_mean/read/_219__cf__219\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/BatchNorm/moving_variance/read/_220__cf__220\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/weights/read/_221__cf__221\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_depthwise/depthwise_weights/read/_222__cf__222\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/BatchNorm/beta/read/_223__cf__223\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/BatchNorm/moving_mean/read/_224__cf__224\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/BatchNorm/moving_variance/read/_225__cf__225\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/weights/read/_226__cf__226\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_depthwise/depthwise_weights/read/_227__cf__227\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/BatchNorm/beta/read/_228__cf__228\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/BatchNorm/moving_mean/read/_229__cf__229\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/BatchNorm/moving_variance/read/_230__cf__230\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/weights/read/_231__cf__231\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_depthwise/depthwise_weights/read/_232__cf__232\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/BatchNorm/beta/read/_233__cf__233\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/BatchNorm/moving_mean/read/_234__cf__234\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/BatchNorm/moving_variance/read/_235__cf__235\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/weights/read/_236__cf__236\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_depthwise/depthwise_weights/read/_237__cf__237\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/BatchNorm/beta/read/_238__cf__238\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/BatchNorm/moving_mean/read/_239__cf__239\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/BatchNorm/moving_variance/read/_240__cf__240\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/weights/read/_241__cf__241\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_depthwise/depthwise_weights/read/_242__cf__242\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/BatchNorm/beta/read/_243__cf__243\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/BatchNorm/moving_mean/read/_244__cf__244\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/BatchNorm/moving_variance/read/_245__cf__245\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/weights/read/_246__cf__246\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_depthwise/depthwise_weights/read/_247__cf__247\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/BatchNorm/beta/read/_248__cf__248\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/BatchNorm/moving_mean/read/_249__cf__249\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/BatchNorm/moving_variance/read/_250__cf__250\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/weights/read/_251__cf__251\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_depthwise/depthwise_weights/read/_252__cf__252\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/BatchNorm/beta/read/_253__cf__253\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/BatchNorm/moving_mean/read/_254__cf__254\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/BatchNorm/moving_variance/read/_255__cf__255\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/weights/read/_256__cf__256\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_depthwise/depthwise_weights/read/_257__cf__257\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/BatchNorm/beta/read/_258__cf__258\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/BatchNorm/moving_mean/read/_259__cf__259\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/BatchNorm/moving_variance/read/_260__cf__260\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/weights/read/_261__cf__261\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_depthwise/depthwise_weights/read/_262__cf__262\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/beta/read/_263__cf__263\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/moving_mean/read/_264__cf__264\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/moving_variance/read/_265__cf__265\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/weights/read/_266__cf__266\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_depthwise/depthwise_weights/read/_267__cf__267\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/BatchNorm/beta/read/_268__cf__268\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/BatchNorm/moving_mean/read/_269__cf__269\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/BatchNorm/moving_variance/read/_270__cf__270\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/weights/read/_271__cf__271\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_depthwise/depthwise_weights/read/_272__cf__272\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/BatchNorm/beta/read/_273__cf__273\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/BatchNorm/moving_mean/read/_274__cf__274\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/BatchNorm/moving_variance/read/_275__cf__275\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/weights/read/_276__cf__276\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_depthwise/depthwise_weights/read/_277__cf__277\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/BatchNorm/beta/read/_278__cf__278\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/BatchNorm/moving_mean/read/_279__cf__279\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/BatchNorm/moving_variance/read/_280__cf__280\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/weights/read/_281__cf__281\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_depthwise/depthwise_weights/read/_282__cf__282\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/BatchNorm/beta/read/_283__cf__283\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/BatchNorm/moving_mean/read/_284__cf__284\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/BatchNorm/moving_variance/read/_285__cf__285\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/weights/read/_286__cf__286\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_depthwise/depthwise_weights/read/_287__cf__287\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/BatchNorm/beta/read/_288__cf__288\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/BatchNorm/moving_mean/read/_289__cf__289\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/BatchNorm/moving_variance/read/_290__cf__290\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/weights/read/_291__cf__291\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_depthwise/depthwise_weights/read/_292__cf__292\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/BatchNorm/beta/read/_293__cf__293\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/BatchNorm/moving_mean/read/_294__cf__294\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/BatchNorm/moving_variance/read/_295__cf__295\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/weights/read/_296__cf__296\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_depthwise/depthwise_weights/read/_297__cf__297\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/BatchNorm/beta/read/_298__cf__298\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/BatchNorm/moving_mean/read/_299__cf__299\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/BatchNorm/moving_variance/read/_300__cf__300\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/weights/read/_301__cf__301\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_depthwise/depthwise_weights/read/_302__cf__302\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/BatchNorm/beta/read/_303__cf__303\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/BatchNorm/moving_mean/read/_304__cf__304\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/BatchNorm/moving_variance/read/_305__cf__305\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/weights/read/_306__cf__306\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_depthwise/depthwise_weights/read/_307__cf__307\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/BatchNorm/beta/read/_308__cf__308\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/BatchNorm/moving_mean/read/_309__cf__309\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/BatchNorm/moving_variance/read/_310__cf__310\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/weights/read/_311__cf__311\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_depthwise/depthwise_weights/read/_312__cf__312\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/BatchNorm/beta/read/_313__cf__313\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/BatchNorm/moving_mean/read/_314__cf__314\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/BatchNorm/moving_variance/read/_315__cf__315\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/weights/read/_316__cf__316\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_depthwise/depthwise_weights/read/_317__cf__317\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/BatchNorm/beta/read/_318__cf__318\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/BatchNorm/moving_mean/read/_319__cf__319\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/BatchNorm/moving_variance/read/_320__cf__320\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/weights/read/_321__cf__321\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_depthwise/depthwise_weights/read/_322__cf__322\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/BatchNorm/beta/read/_323__cf__323\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/BatchNorm/moving_mean/read/_324__cf__324\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/BatchNorm/moving_variance/read/_325__cf__325\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/weights/read/_326__cf__326\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_depthwise/depthwise_weights/read/_327__cf__327\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/BatchNorm/beta/read/_328__cf__328\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/BatchNorm/moving_mean/read/_329__cf__329\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/BatchNorm/moving_variance/read/_330__cf__330\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/weights/read/_331__cf__331\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_depthwise/depthwise_weights/read/_332__cf__332\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/BatchNorm/beta/read/_333__cf__333\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/BatchNorm/moving_mean/read/_334__cf__334\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/BatchNorm/moving_variance/read/_335__cf__335\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/weights/read/_336__cf__336\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_depthwise/depthwise_weights/read/_337__cf__337\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/BatchNorm/beta/read/_338__cf__338\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/BatchNorm/moving_mean/read/_339__cf__339\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/BatchNorm/moving_variance/read/_340__cf__340\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/weights/read/_341__cf__341\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_depthwise/depthwise_weights/read/_342__cf__342\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/BatchNorm/beta/read/_343__cf__343\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/BatchNorm/moving_mean/read/_344__cf__344\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/BatchNorm/moving_variance/read/_345__cf__345\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/weights/read/_346__cf__346\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_depthwise/depthwise_weights/read/_347__cf__347\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/BatchNorm/beta/read/_348__cf__348\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/BatchNorm/moving_mean/read/_349__cf__349\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/BatchNorm/moving_variance/read/_350__cf__350\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/weights/read/_351__cf__351\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_depthwise/depthwise_weights/read/_352__cf__352\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/BatchNorm/beta/read/_353__cf__353\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/BatchNorm/moving_mean/read/_354__cf__354\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/BatchNorm/moving_variance/read/_355__cf__355\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/weights/read/_356__cf__356\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_depthwise/depthwise_weights/read/_357__cf__357\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/BatchNorm/beta/read/_358__cf__358\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/BatchNorm/moving_mean/read/_359__cf__359\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/BatchNorm/moving_variance/read/_360__cf__360\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/weights/read/_361__cf__361\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_depthwise/depthwise_weights/read/_362__cf__362\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/BatchNorm/beta/read/_363__cf__363\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/BatchNorm/moving_mean/read/_364__cf__364\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/BatchNorm/moving_variance/read/_365__cf__365\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/weights/read/_366__cf__366\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_depthwise/depthwise_weights/read/_367__cf__367\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/BatchNorm/beta/read/_368__cf__368\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/BatchNorm/moving_mean/read/_369__cf__369\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/BatchNorm/moving_variance/read/_370__cf__370\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/weights/read/_371__cf__371\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_depthwise/depthwise_weights/read/_372__cf__372\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/BatchNorm/beta/read/_373__cf__373\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/BatchNorm/moving_mean/read/_374__cf__374\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/BatchNorm/moving_variance/read/_375__cf__375\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/weights/read/_376__cf__376\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_depthwise/depthwise_weights/read/_377__cf__377\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/BatchNorm/beta/read/_378__cf__378\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/BatchNorm/moving_mean/read/_379__cf__379\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/BatchNorm/moving_variance/read/_380__cf__380\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/weights/read/_381__cf__381\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_depthwise/depthwise_weights/read/_382__cf__382\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/BatchNorm/beta/read/_383__cf__383\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/BatchNorm/moving_mean/read/_384__cf__384\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/BatchNorm/moving_variance/read/_385__cf__385\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/weights/read/_386__cf__386\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_depthwise/depthwise_weights/read/_387__cf__387\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/BatchNorm/beta/read/_388__cf__388\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/BatchNorm/moving_mean/read/_389__cf__389\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/BatchNorm/moving_variance/read/_390__cf__390\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/weights/read/_391__cf__391\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_depthwise/depthwise_weights/read/_392__cf__392\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/BatchNorm/beta/read/_393__cf__393\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/BatchNorm/moving_mean/read/_394__cf__394\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/BatchNorm/moving_variance/read/_395__cf__395\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/weights/read/_396__cf__396\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_depthwise/depthwise_weights/read/_397__cf__397\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/BatchNorm/beta/read/_398__cf__398\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/BatchNorm/moving_mean/read/_399__cf__399\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/BatchNorm/moving_variance/read/_400__cf__400\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/weights/read/_401__cf__401\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_depthwise/depthwise_weights/read/_402__cf__402\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/BatchNorm/beta/read/_403__cf__403\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/BatchNorm/moving_mean/read/_404__cf__404\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/BatchNorm/moving_variance/read/_405__cf__405\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/weights/read/_406__cf__406\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_depthwise/depthwise_weights/read/_407__cf__407\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/BatchNorm/beta/read/_408__cf__408\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/BatchNorm/moving_mean/read/_409__cf__409\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/BatchNorm/moving_variance/read/_410__cf__410\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/weights/read/_411__cf__411\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_depthwise/depthwise_weights/read/_412__cf__412\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/BatchNorm/beta/read/_413__cf__413\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/BatchNorm/moving_mean/read/_414__cf__414\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/BatchNorm/moving_variance/read/_415__cf__415\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/weights/read/_416__cf__416\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/concat_stage7\n",
      "********* Model Ready *************\n"
     ]
    }
   ],
   "source": [
    "w, h = model_wh(resize)\n",
    "if w > 0 and h > 0:\n",
    "    e = TfPoseEstimator(get_graph_path(model), target_size=(w, h), trt_bool=False)\n",
    "else:\n",
    "    e = TfPoseEstimator(get_graph_path(model), target_size=(432, 368), trt_bool=False)\n",
    "print('********* Model Ready *************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take position from the trainer (dancer):\n",
    "- We made two functions to get all the keypoints from the trainer and store them in a dataframe and in a list.\n",
    "-  The function **\"dance_video_processing\"** is used to predict all the keypoints from the video and return all the keypoints for the video.\n",
    "- The function **\"get_position\"** is used to take all the keypoints that are returned from the above function, preprocess them and return the dataframe and the list of keypoints.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anyio import current_time\n",
    "\n",
    "\n",
    "def dance_video_processing(video_path= r'dance_video/dancer.mp4',showBG = True):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if cap.isOpened() is False:\n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    # fps_time = 0\n",
    "    prev_time = 0\n",
    "    FPS =10\n",
    "    keypoints_list=[]\n",
    "    while True:\n",
    "        ret_val, image = cap.read()\n",
    "        cv2.imshow('Dancer2', image)\n",
    "        current_time = time.time() - prev_time\n",
    "        dim = (368, 428)\n",
    "        if (ret_val is True) and (current_time > 1./FPS):\n",
    "             # resize image\n",
    "            image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "            humans = e.inference(image,\n",
    "                                 resize_to_default=(w > 0 and h > 0),\n",
    "                                 upsample_size=4.0)\n",
    "            if not showBG:\n",
    "                image = np.zeros(image.shape)\n",
    "            # Plotting the keypoints and lines to the image \n",
    "            image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "            npimg = np.copy(image)\n",
    "            image_h, image_w = npimg.shape[:2]\n",
    "            centers = {}\n",
    "            \n",
    "            for human in humans:\n",
    "                      # draw point\n",
    "                    for i in range(common.CocoPart.Background.value):\n",
    "                            if i not in human.body_parts.keys():\n",
    "                                    continue\n",
    "                            body_part = human.body_parts[i]\n",
    "                            x_axis=int(body_part.x * image_w + 0.5)\n",
    "                            y_axis=int(body_part.y * image_h + 0.5) \n",
    "                            center=[x_axis,y_axis]\n",
    "                            centers[i] = center\n",
    "                            keypoints_list.append(centers)\n",
    "            # To display fps\n",
    "            cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - prev_time)), (10, 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # To display image\n",
    "            cv2.imshow('Dancer', image)\n",
    "            prev_time = time.time()\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "        elif (ret_val is False):\n",
    "            break\n",
    "        else:\n",
    "            cv2.waitKey(1)\n",
    "    print(len(keypoints_list))\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return keypoints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dance_video_processing(video_path= r'dance_video/dancer.mp4',showBG = True):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if cap.isOpened() is False:\n",
    "            print(\"Error opening video stream or file\")\n",
    "        fps_time = 0\n",
    "        while True:\n",
    "            ret_val, image = cap.read()\n",
    "            dim = (368, 428)\n",
    "            if ret_val:\n",
    "                 # resize image\n",
    "                image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "                humans = e.inference(image,\n",
    "                                     resize_to_default=(w > 0 and h > 0),\n",
    "                                     upsample_size=4.0)\n",
    "                if not showBG:\n",
    "                    image = np.zeros(image.shape)\n",
    "                # Plotting the keypoints and lines to the image \n",
    "                image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "                npimg = np.copy(image)\n",
    "                image_h, image_w = npimg.shape[:2]\n",
    "                centers = {}\n",
    "                keypoints_list=[]\n",
    "                for human in humans:\n",
    "                          # draw point\n",
    "                        for i in range(common.CocoPart.Background.value):\n",
    "                                if i not in human.body_parts.keys():\n",
    "                                        continue\n",
    "\n",
    "                                body_part = human.body_parts[i]\n",
    "                                x_axis=int(body_part.x * image_w + 0.5)\n",
    "                                y_axis=int(body_part.y * image_h + 0.5) \n",
    "                                center=[x_axis,y_axis]\n",
    "                                centers[i] = center\n",
    "                                keypoints_list.append(centers)\n",
    "                # To display fps\n",
    "                cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                # To display image\n",
    "                cv2.imshow('Dancer', image)\n",
    "                fps_time = time.time()\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "        #print(keypoints_list)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return keypoints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(video_path= r'dance_video/dancer.mp4',showBG = True):\n",
    "    keypoints_list=dance_video_processing()\n",
    "    df = pd.DataFrame(keypoints_list)\n",
    "    df.to_csv(\"keypoints_list\",index=False )\n",
    "    #features=[0]*32\n",
    "    \n",
    "    #print(features)\n",
    "    keyp_list=[]\n",
    "    #data=pd.Dataframe()\n",
    "    print(len(keypoints_list))\n",
    "    # Preprocessing of the keypoints data\n",
    "    for i in range(0, len(keypoints_list)):\n",
    "        k=-2\n",
    "        features=[0]*36\n",
    "        for j in range(0,18):\n",
    "            k=k+2\n",
    "            try:\n",
    "                if k>=36:\n",
    "                    break\n",
    "                #print(k)\n",
    "                #print(keypoints_list[i][j])\n",
    "                features[k]=keypoints_list[i][j][0]\n",
    "                features[k+1]=keypoints_list[i][j][1]\n",
    "            except:\n",
    "                features[k]=0\n",
    "                features[k+1]=0\n",
    "        # print(features)\n",
    "        keyp_list.append(features) # features : 한 프레임의 position 값 \n",
    "    # print(keyp_list)\n",
    "    # Getting all the feature column names for intialization of our dataframe.\n",
    "    column_names=[]\n",
    "    for i in range(36):\n",
    "        column_names.append(str(i))\n",
    "    data=pd.DataFrame(keyp_list,columns=column_names)\n",
    "    return data,keyp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22584\\1527387303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdance_video_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22584\\2718673538.py\u001b[0m in \u001b[0;36mdance_video_processing\u001b[1;34m(video_path, showBG)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mret_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dancer2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mcurrent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprev_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m368\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m428\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "dance_video_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[[152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54], [152, 60, 182, 100, 150, 107, 141, 151, 99, 151, 215, 91, 245, 128, 249, 181, 153, 209, 0, 0, 0, 0, 204, 202, 0, 0, 0, 0, 145, 56, 157, 54, 0, 0, 177, 54]]\n"
     ]
    }
   ],
   "source": [
    "data,keyp_list=get_position()\n",
    "print(keyp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Observation:** \n",
    "- We can see how the keypoints data looks from the above example.\n",
    "- Since they are 18 keypoints and each keypoint has **x-coordinate** and **y-coordinate** we have **36 columns** (18 x 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity:\n",
    "Cosine Similarity function for our model to find the keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineSimilarity_1(source_representation, test_representation):\n",
    "    import numpy as np\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing:\n",
    "Comparing the user images with keypoints of the dancer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_positions(trainer_video,user_video,keyp_list, dim=(420,720)):\n",
    "    cap = cv2.VideoCapture(trainer_video)\n",
    "    cam = cv2.VideoCapture(user_video) \n",
    "    cam.set(3, w)\n",
    "    cam.set(4, h)\n",
    "    # fps_time = 0 #Initializing fps to 0\n",
    "    prev_time = 0\n",
    "    FPS = 0.5\n",
    "    while True:\n",
    "        ret_val, image_1 = cam.read()\n",
    "        e_d=0\n",
    "        ret_val_1,image_2 = cap.read()\n",
    "        current_time = time.time() - prev_time\n",
    "        if ret_val_1 and ret_val and (current_time > 1./FPS):\n",
    "            # resizing the images\n",
    "            image_1 = cv2.resize(image_1, dim, interpolation = cv2.INTER_AREA)\n",
    "            image_2 = cv2.resize(image_2, dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            humans_2 = e.inference(image_1, resize_to_default=(w > 0 and h > 0),upsample_size=4.0 )\n",
    "            dancers_1 = e.inference(image_2,resize_to_default=(w > 0 and h > 0),upsample_size=4.0)\n",
    "            \n",
    "            #Dancer keypoints and normalization\n",
    "            transformer = Normalizer().fit(keyp_list)  \n",
    "            keyp_list=transformer.transform(keyp_list)\n",
    "            \n",
    "            # Showing FPS\n",
    "            cv2.putText(image_2, \"FPS: %f\" % (1.0 / (time.time() - prev_time)), (10, 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "           \n",
    "            # Getting User keypoints, normalization and comparing also plotting the keypoints and lines to the image\n",
    "            image_1 = TfPoseEstimator.draw_humans(image_1, humans_2, imgcopy=False) # 선 표시하는 코드\n",
    "            image_2 = TfPoseEstimator.draw_humans(image_2, dancers_1, imgcopy=False) # 선 표시하는 코드\n",
    "            # Displaying the dancer feed.\n",
    "            cv2.imshow('Dancer Window', image_2)\n",
    "            npimg = np.copy(image_1)\n",
    "            image_h, image_w = npimg.shape[:2]\n",
    "            centers = {}\n",
    "            keypoints_list=[]\n",
    "            for human in humans_2:\n",
    "                          # draw point\n",
    "                    for i in range(common.CocoPart.Background.value):\n",
    "                                if i not in human.body_parts.keys():\n",
    "                                        continue\n",
    "\n",
    "                                body_part = human.body_parts[i]\n",
    "                                x_axis=int(body_part.x * image_w + 0.5)\n",
    "                                y_axis=int(body_part.y * image_h + 0.5)\n",
    "                                center=[x_axis,y_axis]\n",
    "                                centers[i] = center\n",
    "                    k=-2\n",
    "                    features=[0]*36\n",
    "                    for j in range(0,18):\n",
    "                        k=k+2\n",
    "                        try:\n",
    "                            if k>=36:\n",
    "                                break\n",
    "                            #print(k)\n",
    "                            #print(keypoints_list[i][j])\n",
    "                            features[k] = centers[j][0]\n",
    "                            features[k+1] = centers[j][1]\n",
    "                        except:\n",
    "                            features[k]=0\n",
    "                            features[k+1]=0\n",
    "                    features=transformer.transform([features])\n",
    "                    #print(features[0])\n",
    "                    min_=100 # Intializing a value to get minimum cosine similarity score from the dancer array list with the user\n",
    "                    for j in keyp_list:\n",
    "                        #print(j)\n",
    "                        sim_score=findCosineSimilarity_1(j,features[0])\n",
    "                        print(sim_score)\n",
    "                        #print(sim_score)\n",
    "                        #Getting the minimum Cosine Similarity Score\n",
    "                        if min_>sim_score:\n",
    "                            min_=sim_score\n",
    "            # Displaying the minimum cosine score\n",
    "            cv2.putText(image_1, str(min_), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            # If the disctance is below the threshold\n",
    "            if min_<0.15:\n",
    "                cv2.putText(image_1, \"CORRECT STEPS\", (120, 700),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(image_1,  \"NOT CORRECT STEPS\", (80, 700),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image_1, \"FPS: %f\" % (1.0 / (time.time() - prev_time)), (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # Display the user feed\n",
    "            flipped_image = cv2.flip(image_1, 1)\n",
    "            cv2.imshow('User Window', flipped_image)\n",
    "\n",
    "            prev_time = time.time()\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "Since I cant dance, I'll be using a video for this :P.<br> We can replce the **user_video** attribute to **0 or 1** to turn on live camera depending on the type of camera we have.\n",
    "### For a wrong positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n",
      "0.4991436055639674\n"
     ]
    }
   ],
   "source": [
    "compare_positions(r'dance_video/dancer.mp4',0,keyp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a correct positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_positions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14568\\3888672402.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompare_positions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'dance_video/dancer.mp4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeyp_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'compare_positions' is not defined"
     ]
    }
   ],
   "source": [
    "compare_positions(r'dance_video/dancer.mp4',1,keyp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have developed a pose estimation similarity pipeline to compare similarity between two poses from the given feed of videos or live cam.<br>\n",
    "**Flaws:**\n",
    "- This approach fails when the trainer is far or the user is near to the camera or vise-versa. This happens because there is a **scale variation** between the keypoints of the image.<br>\n",
    "**Solution:**\n",
    "- We can eleminate this problem by **croping out the image of a peron** using a CNN architecture like Yolo or anything that could detect the bounding boxes of a person.\n",
    "- This image then can be fed to the openpose model to estimate keypoints for both the sources.<br>\n",
    "**Scope of improvement:**\n",
    "- The accuracy of the model for keypoint prediction can be increased by taking a much powerful pretrained model architecture than mobilenet."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "91a50b50fe1dca752c0f3877fa79a88c54a705a171fcc2d6f84fa1465c71bc30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
