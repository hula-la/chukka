# 1. ì´ˆê¸° ì„¸íŒ…

### í¬ê¸° ì„¤ì • ë° ëª¨ë¸ ì„¤ì •

```python
resize = '432x368'     # resize images before they are processed
resize_out_ratio = 4.0 # resize heatmaps before they are post-processed
model='mobilenet_v2_large'
```

#### ðŸ”Ž mobilenet_v2_large

- ê¸°ì¡´ì˜ mobilenet v1ì—ì„œëŠ” `Depthwise Separable Convolution` ì„ ë„ìž…í•˜ì—¬ ì—°ì‚°ëŸ‰ê³¼ ëª¨ë¸ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì¼ ìˆ˜ ìžˆì–´ì„œ, ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ì™€ ê°™ì€ ë² í•œëœ í™˜ê²½ì—ì„œë„ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•œ NN
- ì´ ëª¨ë¸ì˜ í•µì‹¬ ê°œë…ì€ `Inverted Residual` êµ¬ì¡°
- ì •í™•í•œ ì›ë¦¬ë“¤ì€ ë­”ë§ì¸ì§€ ëª¨ë¥´ê² ê³ , `í•™ìŠµì„ ìœ„í•œ ëª¨ë¸`ì´ë¼ê³  ìƒê°í•˜ë©´ ë  ë“¯.

---

#### Estimator êµ¬ì¶•

```python
from tf_pose.estimator import TfPoseEstimator
from tf_pose.networks import get_graph_path, model_wh

w, h = model_wh(resize)
if w > 0 and h > 0:
    e = TfPoseEstimator(get_graph_path(model), target_size=(w, h), trt_bool=False)
else:
    e = TfPoseEstimator(get_graph_path(model), target_size=(432, 368), trt_bool=False)
print('********* Model Ready *************')
```



# 2. ëŒ„ì„œì˜ ìžì„¸ ì¶”ì¶œ

- íŠ¸ë ˆì´ë„ˆì˜ í‚¤í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•´ì„œ ë¦¬ìŠ¤íŠ¸ì— ì €ìž¥

- `dance_video_processing`: ë¹„ë””ì˜¤ì—ì„œ keypointsì„ ì¶”ì¶œ

  - input
    - video_path: ë¹„ë””ì˜¤ ê²½ë¡œ
    - showBG: ì˜ìƒì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì¶œë ¥ ìœ ë¬´ (ê¸°ë³¸ê°’: True)
  - return
    - keypoints_list: íŠ¸ë ˆì´ë„ˆì˜ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸

  ```python
  def dance_video_processing(video_path= r'dance_video/dancer.mp4',showBG = True):
          cap = cv2.VideoCapture(video_path)
          if cap.isOpened() is False:
              print("Error opening video stream or file")
          fps_time = 0
          while True:
              ret_val, image = cap.read()
              dim = (368, 428)
              if ret_val:
                   # resize image
                  image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)
                  humans = e.inference(image,
                                       resize_to_default=(w > 0 and h > 0),
                                       upsample_size=4.0)
                  if not showBG:
                      image = np.zeros(image.shape)
                  # Plotting the keypoints and lines to the image 
                  image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)
                  npimg = np.copy(image)
                  image_h, image_w = npimg.shape[:2]
                  centers = {}
                  keypoints_list=[]
                  for human in humans:
                            # draw point
                          for i in range(common.CocoPart.Background.value):
                                  if i not in human.body_parts.keys():
                                          continue
  
                                  body_part = human.body_parts[i]
                                  x_axis=int(body_part.x * image_w + 0.5)
                                  y_axis=int(body_part.y * image_h + 0.5) 
                                  center=[x_axis,y_axis]
                                  centers[i] = center
                                  keypoints_list.append(centers)
                  # To display fps
                  cv2.putText(image, "FPS: %f" % (1.0 / (time.time() - fps_time)), (10, 10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                  # To display image
                  cv2.imshow('Dancer', image)
                  fps_time = time.time()
                  if cv2.waitKey(1) & 0xFF == ord('q'):
                      break
                  
              else:
                  break
          #print(keypoints_list)
          cap.release()
          cv2.destroyAllWindows()
          return keypoints_list
  ```

  