## 1. HTTP 통신 - 강사 영상

https://stribny.name/blog/fastapi-video/

##### FrontEnd

```html
<!DOCTYPE html>
<html>
    <head>
        <title>FastAPI video streaming</title>
    </head>
    <body>
        <video width="1200" controls muted="muted">
            <source src="http://localhost:8000/video" type="video/mp4" />
        </video>
    </body>
</html>
```



---

##### 	websocket이 아닌 실시간 영상 스트리밍

​	https://access-violation.tistory.com/17

---

##### - 공식문서 참고해서 영상 보내기 성공

- **html**: `index_2.html`
- **fastAPI**: `fastapi_prac.py`

https://fastapi.tiangolo.com/ko/advanced/custom-response/?h=video#using-streamingresponse-with-file-like-objects

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

some_file_path = "large-video-file.mp4"
app = FastAPI()


@app.get("/")
def main():
    def iterfile():  # 
        with open(some_file_path, mode="rb") as file_like:  # 
            yield from file_like  # 

    return StreamingResponse(iterfile(), media_type="video/mp4")
```

- 공식문서에서 이 외의 코드들 중에서도 참고할 코드 있는지 보기
- 기존의 웹소켓통신도 HTTP로 가능한지 보기

---

## 2. 싱크 맞추기

#### 기존의 강사 자세 데이터 추출 코드 개선

##### a. 깃폴더에 가상환경이랑 전체 옮김

- `No module named '_pafprocess'
  you need to build c++ library for pafprocess. See : https://github.com/ildoonet/tf-pose-estimation/tree/master/tf_pose/pafprocess`

  에러가 떠서 아래 명령으로 환경설정

  ```bash
  cd tf_pose/pafprocess
  swig -python -c++ pafprocess.i && python setup.py build_ext --inplace
  ```

  

##### b. OpenCV API 서칭 (https://deepflowest.tistory.com/107)

- ##### 동영상 및 카메라 프레임 읽기

  - `cap = cv2.VideoCaputure(file_path 또는 index)` : 비디오 캡처 객체 생성

    - file_path : 동영상 파일 경로
    - index : 카메라 장치 번호 (0 부터 차례로 증가)
    - cap : VideoCapture 객체

    - `ret = cap.isOpened()` : 객체 초기화 확인
      - ret : 초기화 여부, True/False

    - `ret, img = cap.read() : 영상 프레임 읽기`
      - ret : 프레임 읽기 성송 또는 실패 여부, True / False
      - img : 프레임 이미지, Numpy 배열 또는 None

  - `cap.set(id, value)` : 프로퍼티 변경

  - `cap.get(id)` : 프로퍼티 확인

  - `cap.release()` : 객체 자원 반납

- ##### 카메라 비디오 속성 제어

  - cv2.CAP_PROP_FRAME_WIDTH : 프레임 폭
  - cv2.CAP_PROP_FRAME_HEIGHT : 프레임 높이
  - cv2.CAP_PROP_FPS : 프레임 초당 프레임 수
  - cv2.CAP_PROP_POS_MSEC : 동영상 파일의 프레임 위치(MS)
  - cv2.CAP_PROP_POS_AVI_RATIO : 동영상 파일의 상대 위치 (0:시작 , 1:끝)
  - cv2.CAP_PROP_FOURCC : 동영상 파일 코덱 문자
  - cv2.CAP_PROP_AUTOFOCUS : 카메라 자동 초점 조절
  - cv2.CAP_PROP_ZOOM : 카메라 줌

- ##### FPS를 지정해서 동영상 재성

  - 동영상의 FPS를 구하고 다음과 같이 적절한 지연 시간을 계산해서 지정할 수 있다.

    ```python
    fps = cap.get(cv2.CP_PROP_FPS)
    delay = int(1000/fps)
    ```

    ```python
    import cv2
    
    video_file = "img/a.mp4"
    
    cap = cv2.VideoCapture(video_file)
    if cap.isOpened():
    	fps = cap.get(cv2.CAP_PROP_FPS)
        delay = int(1000/fps)
        print("FPS: %f, Delay: %dms" %(fps, delay))
        
        while True:
            ret, img = cap.read()
            if ret:
                cv2.imshow(video_file, img)
                cv2.waitKey(delay)
            else:
                break
    else:
    	print("can't open video")
    cap.release()
    cv2.destroyAllWindows()
    ```

##### c. 코드 수정

- 기존엔 강사 자세 좌표 갯수가 실제 추출되어야할 프레임 수와 달랐음. 3400정도
  - 코드 분석 후 수정 완료 
    - 영상길이 21초
    - FPS 10 설정
    - **추출된 프레임 갯수 214** 👍

- `dance_video_processing`

  ```python
  def dance_video_processing(video_path= r'dance_video/correct30.mp4',showBG = True):
  
      cap = cv2.VideoCapture(video_path)
      video_fps = cap.get(cv2.CAP_PROP_FPS)
      # delay 추가, 실제 비디오 fps로 조절함
      delay = int(1000/video_fps)
  
      if cap.isOpened() is False:
          print("Error opening video stream or file")
  
      # prev_time = 0 -> 맨처음 시간 초기화 수정
      prev_time = time.time()
      FPS = 10
      keypoints_list=[]
      
      while True:
          ret_val, image = cap.read()
          current_time = time.time() - prev_time
          dim = (368, 428)
          if (ret_val is True) and (current_time > 1./FPS) :
              image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)
              humans = e.inference(image,
                                   resize_to_default=(w > 0 and h > 0),
                                   upsample_size=4.0)
              if not showBG:
                  image = np.zeros(image.shape)
  
              image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)
              npimg = np.copy(image)
              image_h, image_w = npimg.shape[:2]
              centers = {}
              
              for human in humans:
                      for i in range(common.CocoPart.Background.value):
                              if i not in human.body_parts.keys():
                                      continue
                              body_part = human.body_parts[i]
                              x_axis=int(body_part.x * image_w + 0.5)
                              y_axis=int(body_part.y * image_h + 0.5) 
                              center=[x_axis,y_axis]
                              centers[i] = center
                      # 수정 : 한 묶음이 append 되도록 수정
                      keypoints_list.append(centers)
  
              cv2.putText(image, "FPS: %f" % (1.0 / (time.time() - prev_time)), (10, 10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
              
              cv2.imshow('Dancer', image) 
  
              prev_time = time.time() 
  
              if cv2.waitKey(1) & 0xFF == ord('q'):
                  break
            
          elif (ret_val is False) :
              break
          else:
              # cv2.waitKey(1) => 데이터 분석 안할 때는 delay 초 만큼 지연되도록 수정
              image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)
              cv2.imshow('Dancer', image) 
              cv2.waitKey(delay)
              
      print(len(keypoints_list))
      cap.release()
      cv2.destroyAllWindows()
      return keypoints_list
  ```

  

##### d. 댄서 자세 데이터 csv 입출력

- 저장

  ```python
  data.to_csv("dancer_keyp_list.csv", index=False, header=False)
  ```

- 읽기

  ```python
  keyp_list=np.genfromtxt("dancer_keyp_list.csv",delimiter=",")
  ```

  

##### e. FPS 수정

- 실제 예상 프레임 수와 약간 차이가 생김
  - 이전엔 괜찮았는데, 갑자기 210->190 정도로 줄어듦
  - 분석할 때 실제 FPS보다 느려서 생기는 딜레이같아서 FPS를 5로 줄이니 105로 예상 프레임 수와 같아짐.